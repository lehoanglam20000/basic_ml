{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a65cdc",
   "metadata": {},
   "source": [
    "L1 and L2 regularization are techniques used to prevent overfitting in machine learning models by adding a penalty to the loss function. These penalties help to constrain the model's complexity, encouraging simpler models that generalize better to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c3aba",
   "metadata": {},
   "source": [
    "L1 regularization, also known as Lasso (Least Absolute Shrinkage and Selection Operator), adds a penalty equal to the absolute value of the magnitude of coefficients. The L1 penalty can lead to sparse models, where some coefficients are exactly zero, effectively performing feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b762a4f",
   "metadata": {},
   "source": [
    "L2 regularization, also known as Ridge, adds a penalty equal to the square of the magnitude of coefficients. The L2 penalty encourages smaller coefficients, but unlike L1, it does not lead to sparse models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
